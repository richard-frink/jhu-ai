{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "1. Change the name of this file to be your JHED id as in `jsmith299.ipynb`. Because sure you use your JHED ID (it's made out of your name and not your student id which is just letters and numbers).\n",
    "2. Make sure the notebook you submit is cleanly and fully executed. I do not grade unexecuted notebooks.\n",
    "3. Submit your notebook back in Blackboard where you downloaded this file.\n",
    "\n",
    "*Provide the output **exactly** as requested*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k Nearest Neighbors and Model Evaluation\n",
    "\n",
    "In this programming assignment you will use k Nearest Neighbors (kNN) to build a \"model\" that will estimate the compressive strength of various types of concrete. This assignment has several objectives:\n",
    "\n",
    "1. Implement the kNN algorithm with k=9. Remember...the data + distance function is the model in kNN. In addition to asserts that unit test your code, you should \"test drive\" the model, showing output that a non-technical person could interpret.\n",
    "\n",
    "2. You are going to compare the kNN model above against the baseline model described in the course notes (the mean of the training set's target variable). You should use 10 fold cross validation and Mean Squared Error (MSE):\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum^n_i (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "as the evaluation metric (\"error\"). Refer to the course notes for the format your output should take. Don't forget a discussion of the results.\n",
    "\n",
    "3. use validation curves to tune a *hyperparameter* of the model. \n",
    "In this case, the hyperparameter is *k*, the number of neighbors. Don't forget a discussion of the results.\n",
    "\n",
    "4. evaluate the *generalization error* of the new model.\n",
    "Because you may have just created a new, better model, you need a sense of its generalization error, calculate that. Again, what would you like to see as output here? Refer to the course notes. Don't forget a discussion of the results. Did the new model do better than either model in Q2?\n",
    "\n",
    "5. pick one of the \"Choose Your Own Adventure\" options.\n",
    "\n",
    "Refer to the \"course notes\" for this module for most of this assignment.\n",
    "Anytime you just need test/train split, use fold index 0 for the test set and the remainder as the training set.\n",
    "Discuss any results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "The function `parse_data` loads the data from the specified file and returns a List of Lists. The outer List is the data set and each element (List) is a specific observation. Each value of an observation is for a particular measurement. This is what we mean by \"tidy\" data.\n",
    "\n",
    "The function also returns the *shuffled* data because the data might have been collected in a particular order that *might* bias training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import statistics\n",
    "import scipy\n",
    "from typing import List, Dict, Tuple, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> List[List]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = [float(value) for value in line.rstrip().split(\",\")]\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse_data(\"concrete_compressive_strength.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[366.0, 187.0, 0.0, 191.3, 6.6, 824.3, 756.9, 28.0, 65.91]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1,030 observations and each observation has 8 measurements. The data dictionary for this data set tells us the definitions of the individual variables (columns/indices):\n",
    "\n",
    "| Index | Variable | Definition |\n",
    "|-------|----------|------------|\n",
    "| 0     | cement   | kg in a cubic meter mixture |\n",
    "| 1     | slag     | kg in a cubic meter mixture |\n",
    "| 2     | ash      | kg in a cubic meter mixture |\n",
    "| 3     | water    | kg in a cubic meter mixture |\n",
    "| 4     | superplasticizer | kg in a cubic meter mixture |\n",
    "| 5     | coarse aggregate | kg in a cubic meter mixture |\n",
    "| 6     | fine aggregate | kg in a cubic meter mixture |\n",
    "| 7     | age | days |\n",
    "| 8     | concrete compressive strength | MPa |\n",
    "\n",
    "The target (\"y\") variable is a Index 8, concrete compressive strength in (Mega?) [Pascals](https://en.wikipedia.org/wiki/Pascal_(unit))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Splits - n folds\n",
    "\n",
    "With n fold cross validation, we divide our data set into n subgroups called \"folds\" and then use those folds for training and testing. You pick n based on the size of your data set. If you have a small data set--100 observations--and you used n=10, each fold would only have 10 observations. That's probably too small. You want at least 30. At the other extreme, we generally don't use n > 10.\n",
    "\n",
    "With 1,030 observations, n = 10 is fine so we will have 10 folds.\n",
    "`create_folds` will take a list (xs) and split it into `n` equal folds with each fold containing one-tenth of the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(xs: List, n: int) -> List[List[List]]:\n",
    "    k, m = divmod(len(xs), n)\n",
    "    # be careful of generators...\n",
    "    return list(xs[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = create_folds(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always use one of the n folds as a test set (and, sometimes, one of the folds as a *pruning* set but not for kNN), and the remaining folds as a training set.\n",
    "We need a function that'll take our n folds and return the train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(folds: List[List[List]], index: int) -> Tuple[List[List], List[List]]:\n",
    "    training = []\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = training + fold\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the function to give us a train and test datasets where the test set is the fold at index 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = create_train_test(folds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers\n",
    "\n",
    "Answer the questions above in the space provided below, adding cells as you need to.\n",
    "Put everything in the helper functions and document them.\n",
    "Document everything (what you're doing and why).\n",
    "If you're not sure what format the output should take, refer to the course notes and what they do for that particular topic/algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: kNN\n",
    "\n",
    "Implement k Nearest Neighbors with k = 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"distance\"></a>\n",
    "## distance\n",
    "\n",
    "Calculates distance using a modified euclidean distance (euclidean distance without the final square root) for each index in the provided lists. Lists must be equal length.\n",
    "\n",
    "Variables\n",
    "* **p1** List: values to use for calculating distance\n",
    "* **p2** List: second set of values to use for calculating distance\n",
    "\n",
    "**returns** float: the sum of every distance between all values in the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(p1: List, p2: List):\n",
    "    return sum([(p1[i]-p2[i])**2 for i in range(len(p1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert distance([0,0], [1,1]) == 2\n",
    "assert distance([0,0,0], [2,2,1.5]) == 10.25\n",
    "assert distance([1,1.5,0.2], [5,1,0.4]) == 16.29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"find_neighbors\"></a>\n",
    "## find_neighbors\n",
    "\n",
    "Finds k-nearest neighbors for a specified index from the test data in the training data.\n",
    "\n",
    "Variables\n",
    "* **training_data** List[List]: List of Lists that are the concrete information - should be the training set\n",
    "* **test_data** List[List]: List of Lists that are the concrete information - should be the training set\n",
    "* **test_index** int: the index to get the test_row from in the test_data\n",
    "* **k** int: the number of nearest neighbors to return\n",
    "\n",
    "**returns** List[Tuple(List, float)]: the list of tuples that has a single row of training data and the distance to the test_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbors(training_data: List[List], test_data: List[List], test_index: int, k: int):\n",
    "    distances = []\n",
    "    for training_row in training_data:\n",
    "        distances.append((distance(training_row, test_data[test_index]), training_row))\n",
    "    distances.sort(key=lambda tup: tup[0])\n",
    "    neighbors = []\n",
    "    for i in range(k):\n",
    "        neighbors.append(distances[i])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_training_data = [[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4]]\n",
    "t2_training_data = [[1,1,1,1],[3,3,3,3],[5,5,5,5],[31,31,31,33],[5,5,5,333]]\n",
    "t1_test_data = [[2,2,2,2],[3,3,3,3],[4,4,4,4],[5,5,5,5]]\n",
    "t2_test_data = [[2,2,2,2],[3,3,3,3],[4,4,4,4],[44,44,44,44]]\n",
    "assert find_neighbors(t1_training_data, t1_test_data, 2, 2) == [(0, [4, 4, 4, 4]), (4, [3, 3, 3, 3])]\n",
    "assert find_neighbors(t2_training_data, t1_test_data, 3, 2) == [(0, [5, 5, 5, 5]), (16, [3, 3, 3, 3])]\n",
    "assert find_neighbors(t1_training_data, t2_test_data, 3, 2) == [(6400, [4, 4, 4, 4]), (6724, [3, 3, 3, 3])]\n",
    "assert find_neighbors(t2_training_data, t2_test_data, 3, 2) == [(628, [31, 31, 31, 33]), (6084, [5, 5, 5, 5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row with index 35 being tested: 290.4, 0.0, 96.2, 168.1, 9.4, 961.2, 865.0, 3.0, 22.5\n",
      "closest neighbor rank 1: distance=111.31, Row: 295.7, 0.0, 95.6, 171.5, 8.9, 955.1, 859.2, 3.0, 22.95\n",
      "closest neighbor rank 2: distance=269.11, Row: 290.4, 0.0, 96.2, 168.1, 9.4, 961.2, 865.0, 14.0, 34.67\n",
      "closest neighbor rank 3: distance=394.16, Row: 295.7, 0.0, 95.6, 171.5, 8.9, 955.1, 859.2, 14.0, 35.23\n",
      "closest neighbor rank 4: distance=774.82, Row: 290.4, 0.0, 96.2, 168.1, 9.4, 961.2, 865.0, 28.0, 34.74\n",
      "closest neighbor rank 5: distance=1010.96, Row: 277.1, 0.0, 97.4, 160.6, 11.8, 973.9, 875.6, 14.0, 41.89\n",
      "closest neighbor rank 6: distance=1040.26, Row: 295.7, 0.0, 95.6, 171.5, 8.9, 955.1, 859.2, 28.0, 39.94\n",
      "closest neighbor rank 7: distance=1803.6, Row: 277.1, 0.0, 97.4, 160.6, 11.8, 973.9, 875.6, 28.0, 48.28\n",
      "closest neighbor rank 8: distance=2128.38, Row: 250.0, 0.0, 95.7, 187.4, 5.5, 956.9, 861.2, 3.0, 13.82\n",
      "closest neighbor rank 9: distance=2179.9, Row: 250.0, 0.0, 95.7, 187.4, 5.5, 956.9, 861.2, 14.0, 24.92\n"
     ]
    }
   ],
   "source": [
    "k = 9\n",
    "test_index = 35\n",
    "test_row = test[test_index]\n",
    "nearest_neighbors = find_neighbors(train, test, test_index, k)\n",
    "output = 'Row with index ' + str(test_index) + ' being tested: ' + ', '.join([str(e) for e in test_row])\n",
    "for i in range(len(nearest_neighbors)):\n",
    "    output += '\\r\\nclosest neighbor rank ' + str(i + 1) + ': distance=' + str(round(nearest_neighbors[i][0], 2)) + ', Row: ' + ', '.join([str(e) for e in nearest_neighbors[i][1]])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Evaluation vs. The Mean\n",
    "\n",
    "Using Mean Squared Error (MSE) as your evaluation metric, evaluate your implement above and the Null model, the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rotate through using 10 folds\n",
    "calculate the 'y' for 10 random test points in each fold instance\n",
    "    in those calculations, get the MSE of the prediction vs the actual\n",
    "get the average of these MSE\n",
    "then get the standard deviation of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mse\"></a>\n",
    "## mse\n",
    "\n",
    "Calculates Mean Squared Error (MSE) -- Lists must be equal length since it comparing point to point.\n",
    "\n",
    "Variables\n",
    "* **y** List: values to use for calculating distance\n",
    "* **yh** List: second set of values to use for calculating distance\n",
    "\n",
    "**returns** float: MSE of the list compared to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y: List, yh: List):\n",
    "    return (sum([(y[i]-yh[i])**2 for i in range(len(y))]))/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mse([0,0], [1,1]) == 1\n",
    "assert mse([0,0,0], [2,2,1.5]) == 10.25/3\n",
    "assert mse([1,1.5,0.2], [5,1,0.4]) == 16.29/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate_model\"></a>\n",
    "## evaluate_model\n",
    "\n",
    "Evaluates the model by running a 10 fold cross validation and MSE. We will find the average error and the standard deviation.\n",
    "\n",
    "Variables\n",
    "* **folds** List[List[List]]: list of lists of lists.... basically this is the dataset broken up into n-many folds\n",
    "* **k** int: this is the value of k to use for finding neighbors\n",
    "* **should_print_full** bool: this will determine whether to print out full details or just the final MSE and Std dev values\n",
    "\n",
    "**returns** float, float: this prints out the metrics if ou tell it to, and it also returns the avg_mse and the standard deviation of that avg_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(evaluation_folds: List[List[List]], k: int, should_print_full):\n",
    "    mses = []\n",
    "    for i in range(len(evaluation_folds)):\n",
    "        fold_results, y, yh = [], [], []\n",
    "        train, test = create_train_test(evaluation_folds, i)\n",
    "        for n in range(10):\n",
    "            random_index = random.randint(0, len(test) - 1)\n",
    "            nearest_neighbors = find_neighbors(train, test, random_index, k)\n",
    "            y.append(test[random_index][8])\n",
    "            yh.append(nearest_neighbors[0][1][8])\n",
    "            fold_results.append((i, n, random_index, test[random_index][8], nearest_neighbors[0][1][8], test[random_index], nearest_neighbors))\n",
    "        error = round(mse(y, yh), 6)\n",
    "        if should_print_full:\n",
    "            print('\\r\\nFold ' + str(i) + ' Results:\\r\\nMSE Error: ' + str(error))\n",
    "            print('Y (real) values:       ' + ', '.join([str(x) for x in y]))\n",
    "            print('Yh (predicted) values: ' + ', '.join([str(x) for x in yh]))\n",
    "        mses.append(error)\n",
    "    avg_error = sum(mses)/len(mses)\n",
    "    if should_print_full:\n",
    "        print('\\r\\nAverage MSE: ' + str(round(avg_error, 6)))\n",
    "        print('MSE Standard Deviation: ' + str(round(statistics.stdev(mses, avg_error), 6)))\n",
    "    return str(round(avg_error, 6)), str(round(statistics.stdev(mses, avg_error), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 Results:\n",
      "MSE Error: 8.61554\n",
      "Y (real) values:       60.2, 40.93, 24.0, 71.3, 40.56, 39.42, 40.15, 15.82, 13.36, 55.9\n",
      "Yh (predicted) values: 56.7, 40.93, 24.0, 71.3, 36.45, 39.42, 43.58, 15.52, 20.08, 55.9\n",
      "\n",
      "Fold 1 Results:\n",
      "MSE Error: 66.8507\n",
      "Y (real) values:       46.2, 26.97, 46.2, 44.09, 63.4, 40.29, 57.21, 49.2, 41.94, 40.29\n",
      "Yh (predicted) values: 34.4, 29.87, 34.4, 36.94, 77.3, 32.11, 57.22, 49.2, 43.8, 32.11\n",
      "\n",
      "Fold 2 Results:\n",
      "MSE Error: 68.26273\n",
      "Y (real) values:       56.14, 33.66, 48.59, 40.23, 30.57, 71.99, 49.77, 35.34, 47.13, 56.7\n",
      "Yh (predicted) values: 55.25, 16.89, 51.72, 45.71, 17.54, 78.8, 49.77, 38.56, 50.77, 45.7\n",
      "\n",
      "Fold 3 Results:\n",
      "MSE Error: 37.13487\n",
      "Y (real) values:       52.44, 35.23, 61.24, 39.29, 26.15, 61.24, 56.34, 26.91, 39.61, 21.07\n",
      "Yh (predicted) values: 52.45, 35.23, 61.23, 38.6, 26.14, 61.23, 47.97, 15.69, 46.23, 9.62\n",
      "\n",
      "Fold 4 Results:\n",
      "MSE Error: 53.77536\n",
      "Y (real) values:       29.0, 32.53, 2.33, 47.74, 32.72, 37.92, 47.81, 13.12, 46.25, 44.3\n",
      "Yh (predicted) values: 45.7, 43.25, 7.72, 42.92, 33.61, 29.55, 45.85, 17.22, 46.24, 44.7\n",
      "\n",
      "Fold 5 Results:\n",
      "MSE Error: 55.89805\n",
      "Y (real) values:       50.6, 37.17, 8.2, 18.13, 17.28, 65.2, 38.7, 38.7, 28.63, 25.48\n",
      "Yh (predicted) values: 30.85, 37.17, 10.22, 20.97, 7.68, 65.2, 39.38, 39.38, 35.57, 21.54\n",
      "\n",
      "Fold 6 Results:\n",
      "MSE Error: 76.17349\n",
      "Y (real) values:       53.69, 53.46, 38.07, 24.0, 41.54, 28.63, 7.4, 16.89, 14.84, 28.24\n",
      "Yh (predicted) values: 50.66, 41.41, 43.25, 24.0, 33.4, 28.63, 23.51, 9.69, 18.91, 14.59\n",
      "\n",
      "Fold 7 Results:\n",
      "MSE Error: 81.42535\n",
      "Y (real) values:       39.66, 15.09, 21.91, 37.91, 52.52, 35.75, 31.18, 52.52, 44.14, 65.2\n",
      "Yh (predicted) values: 43.38, 15.09, 47.4, 35.76, 53.3, 38.61, 31.18, 53.3, 55.83, 65.2\n",
      "\n",
      "Fold 8 Results:\n",
      "MSE Error: 14.22846\n",
      "Y (real) values:       25.22, 17.37, 43.38, 36.45, 8.49, 37.68, 43.38, 11.85, 32.1, 9.31\n",
      "Yh (predicted) values: 25.18, 17.57, 39.66, 32.72, 13.82, 35.85, 39.66, 17.24, 38.07, 11.36\n",
      "\n",
      "Fold 9 Results:\n",
      "MSE Error: 45.74958\n",
      "Y (real) values:       22.44, 46.23, 32.76, 51.04, 12.55, 47.4, 68.75, 25.18, 41.41, 34.2\n",
      "Yh (predicted) values: 22.44, 53.52, 32.77, 61.92, 9.45, 36.99, 66.78, 20.77, 32.9, 42.7\n",
      "\n",
      "Average MSE: 50.811413\n",
      "MSE Standard Deviation: 24.739506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('50.811413', '24.739506')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(folds, 9, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Hyperparameter Tuning\n",
    "\n",
    "Tune the value of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for k = 1\n",
      "Average MSEs: 54.0682\n",
      "Average Stdev: 27.8439\n",
      "\n",
      "Results for k = 2\n",
      "Average MSEs: 51.6415\n",
      "Average Stdev: 27.8751\n",
      "\n",
      "Results for k = 3\n",
      "Average MSEs: 52.9113\n",
      "Average Stdev: 29.4842\n",
      "\n",
      "Results for k = 4\n",
      "Average MSEs: 47.8167\n",
      "Average Stdev: 25.0591\n",
      "\n",
      "Results for k = 5\n",
      "Average MSEs: 52.3947\n",
      "Average Stdev: 31.699\n",
      "\n",
      "Results for k = 6\n",
      "Average MSEs: 51.1038\n",
      "Average Stdev: 29.4388\n",
      "\n",
      "Results for k = 7\n",
      "Average MSEs: 52.654\n",
      "Average Stdev: 27.8215\n",
      "\n",
      "Results for k = 8\n",
      "Average MSEs: 50.0101\n",
      "Average Stdev: 26.9064\n",
      "\n",
      "Results for k = 9\n",
      "Average MSEs: 52.9684\n",
      "Average Stdev: 30.5497\n",
      "\n",
      "Results for k = 10\n",
      "Average MSEs: 54.4429\n",
      "Average Stdev: 33.5244\n",
      "\n",
      "Results for k = 11\n",
      "Average MSEs: 49.0368\n",
      "Average Stdev: 28.0206\n",
      "\n",
      "Results for k = 12\n",
      "Average MSEs: 52.1191\n",
      "Average Stdev: 26.6053\n",
      "\n",
      "Results for k = 13\n",
      "Average MSEs: 51.387\n",
      "Average Stdev: 32.0818\n",
      "\n",
      "Results for k = 14\n",
      "Average MSEs: 52.1661\n",
      "Average Stdev: 28.8071\n",
      "\n",
      "Results for k = 15\n",
      "Average MSEs: 54.7486\n",
      "Average Stdev: 31.3698\n",
      "\n",
      "Results for k = 16\n",
      "Average MSEs: 52.3512\n",
      "Average Stdev: 32.8684\n",
      "\n",
      "Results for k = 17\n",
      "Average MSEs: 52.6475\n",
      "Average Stdev: 30.2416\n",
      "\n",
      "Results for k = 18\n",
      "Average MSEs: 52.8985\n",
      "Average Stdev: 33.4593\n",
      "\n",
      "Results for k = 19\n",
      "Average MSEs: 53.4259\n",
      "Average Stdev: 31.0296\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 20):\n",
    "    print('\\r\\nResults for k = ' + str(i))\n",
    "    errors = []\n",
    "    stdvs = []\n",
    "    for n in range(20):\n",
    "        avg_error, stdv = evaluate_model(folds, i, False)\n",
    "        errors.append(float(avg_error))\n",
    "        stdvs.append(float(stdv))\n",
    "    avg_e = round(sum(errors)/len(errors), 4)\n",
    "    avg_s = round(sum(stdvs)/len(stdvs), 4)\n",
    "    print('Average MSEs: ' + str(avg_e))\n",
    "    print('Average Stdev: ' + str(avg_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Generalization Error\n",
    "\n",
    "Analyze and discuss the generalization error of your model with the value of k from Problem 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran the model for values of k = 1 through 19, and ran 20 iterations for each k value. I then averaged the MSEs and stdevs.\n",
    "\n",
    "k = 12 showed the most promising results:\n",
    "\n",
    "Average MSEs: 58.497 <- second lowest MSE\n",
    "\n",
    "Average Stdev: 31.4172 <- lowest stdev, and second lowest is at k = 11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Choose your own adventure\n",
    "\n",
    "You have three options for the next part:\n",
    "\n",
    "1. You can implement mean normalization (also called \"z-score standardization\") of the *features*; do not normalize the target, y. See if this improves the generalization error of your model (middle).\n",
    "\n",
    "2. You can implement *learning curves* to see if more data would likely improve your model (easiest).\n",
    "\n",
    "3. You can implement *weighted* kNN and use the real valued GA to choose the weights. weighted kNN assigns a weight to each item in the Euclidean distance calculation. For two points, j and k:\n",
    "$$\\sqrt{\\sum w_i (x^k_i - x^j_i)^2}$$\n",
    "\n",
    "You can think of normal Euclidean distance as the case where $w_i = 1$ for all features  (ambitious, but fun...you need to start EARLY because it takes a really long time to run).\n",
    "\n",
    "The easier the adventure the more correct it must be..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"normalize_data\"></a>\n",
    "## normalize_data\n",
    "\n",
    "This takes the original data set and returns it as the z-score standardized version (not standardizing y / index 8).\n",
    "\n",
    "Variables\n",
    "* **to_normalize** List[List]: values from the concrete csv\n",
    "\n",
    "**returns** List[List]: z score standardized values of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(to_normalize: List):\n",
    "    standardized = []\n",
    "    for c in range(len(to_normalize[0]) - 1):\n",
    "        c_mean = sum([to_normalize[x][c] for x in range(len(to_normalize))])/len(to_normalize)\n",
    "        c_stdev = statistics.stdev([to_normalize[x][c] for x in range(len(to_normalize))])\n",
    "        for r in range(len(to_normalize)):\n",
    "            if c == 0:\n",
    "                standardized.append([])\n",
    "            standardized[r].append(round((to_normalize[r][c] - c_mean)/c_stdev, 6))\n",
    "    for r in range(len(to_normalize)):\n",
    "        standardized[r].append(to_normalize[r][len(to_normalize[r]) - 1])\n",
    "    return standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 Results:\n",
      "MSE Error: 0.42948\n",
      "Y (real) values:       15.82, 34.9, 58.61, 48.7, 10.54, 17.96, 26.85, 61.07, 71.3, 41.05\n",
      "Yh (predicted) values: 15.52, 33.4, 59.3, 49.19, 10.54, 17.28, 26.06, 61.46, 71.3, 41.05\n",
      "\n",
      "Fold 1 Results:\n",
      "MSE Error: 0.49427\n",
      "Y (real) values:       12.46, 44.09, 49.9, 18.03, 15.05, 40.29, 19.69, 23.84, 36.8, 23.22\n",
      "Yh (predicted) values: 12.46, 42.42, 49.8, 18.03, 14.99, 39.0, 19.69, 23.84, 36.8, 22.53\n",
      "\n",
      "Fold 2 Results:\n",
      "MSE Error: 0.81945\n",
      "Y (real) values:       46.23, 17.57, 47.13, 24.44, 55.6, 55.64, 66.1, 47.03, 12.64, 56.1\n",
      "Yh (predicted) values: 45.84, 17.37, 45.71, 25.89, 56.61, 55.83, 65.2, 47.81, 11.47, 55.9\n",
      "\n",
      "Fold 3 Results:\n",
      "MSE Error: 0.73942\n",
      "Y (real) values:       12.47, 40.86, 37.92, 40.86, 26.05, 29.07, 43.58, 50.24, 19.42, 40.86\n",
      "Yh (predicted) values: 11.98, 42.33, 37.36, 42.33, 26.4, 29.07, 43.57, 51.04, 20.73, 40.66\n",
      "\n",
      "Fold 4 Results:\n",
      "MSE Error: 0.22763\n",
      "Y (real) values:       27.04, 12.46, 36.84, 8.54, 29.65, 38.56, 24.66, 20.73, 20.73, 38.56\n",
      "Yh (predicted) values: 27.34, 12.46, 35.75, 8.54, 29.93, 38.5, 24.92, 20.08, 20.08, 38.5\n",
      "\n",
      "Fold 5 Results:\n",
      "MSE Error: 0.5116\n",
      "Y (real) values:       31.38, 77.3, 60.28, 50.6, 66.6, 7.51, 39.42, 33.94, 32.85, 25.51\n",
      "Yh (predicted) values: 32.05, 77.3, 60.29, 51.06, 64.9, 8.06, 39.42, 33.36, 33.73, 25.12\n",
      "\n",
      "Fold 6 Results:\n",
      "MSE Error: 0.2791\n",
      "Y (real) values:       15.52, 48.97, 40.2, 42.55, 59.8, 55.45, 49.77, 32.96, 13.57, 31.45\n",
      "Yh (predicted) values: 15.53, 48.72, 41.3, 42.92, 59.89, 55.83, 49.77, 32.96, 14.64, 31.74\n",
      "\n",
      "Fold 7 Results:\n",
      "MSE Error: 0.44362\n",
      "Y (real) values:       41.3, 49.2, 42.35, 19.01, 15.36, 21.06, 58.78, 28.68, 42.62, 31.18\n",
      "Yh (predicted) values: 40.2, 49.2, 41.16, 19.01, 15.42, 21.5, 59.76, 28.47, 41.84, 31.18\n",
      "\n",
      "Fold 8 Results:\n",
      "MSE Error: 0.25678\n",
      "Y (real) values:       33.31, 32.33, 6.88, 33.56, 27.23, 3.32, 23.89, 6.88, 33.09, 33.56\n",
      "Yh (predicted) values: 33.3, 32.72, 6.28, 33.54, 27.68, 2.33, 24.58, 6.28, 32.9, 33.54\n",
      "\n",
      "Fold 9 Results:\n",
      "MSE Error: 0.26074\n",
      "Y (real) values:       22.44, 43.57, 55.06, 50.08, 41.64, 21.48, 7.84, 14.64, 36.94, 37.44\n",
      "Yh (predicted) values: 22.44, 43.58, 54.38, 51.26, 42.42, 21.82, 8.0, 14.59, 36.94, 37.42\n",
      "\n",
      "Average MSE: 0.446209\n",
      "MSE Standard Deviation: 0.204976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.446209', '0.204976')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the new z score normalized data\n",
    "normalized_data = normalize_data(data)\n",
    "folds = create_folds(normalized_data, 10)\n",
    "evaluate_model(folds, 9, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the standardized data show the error to be significantly smaller, which definitely makes sense due to the smaller differences between raw vs normalized values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Did you provide output exactly as requested?\n",
    "2. Did you re-execute the entire notebook? (\"Restart Kernel and Rull All Cells...\")\n",
    "3. If you did not complete the assignment or had difficulty please explain what gave you the most difficulty in the Markdown cell below.\n",
    "4. Did you change the name of the file to `jhed_id.ipynb`?\n",
    "\n",
    "Do not submit any other files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en605645)",
   "language": "python",
   "name": "en605645"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "117px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
